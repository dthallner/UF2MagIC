{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9bfbea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcd4ba27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start new Magic contribution for a locality\n",
    "\n",
    "sites_dict = {'site': [], 'method_codes': [], 'citations': []}\n",
    "samples_dict = {'site': [], 'sample': [],'method_codes': [], 'citations': [],\n",
    "                'azimuth': [], 'dip': [], 'bed_dip_direction': [], 'bed_dip': [],'result_quality': []}\n",
    "specimens_dict = {'specimen': [], 'sample': [],'method_codes': [],'experiments': [],'volume': [], 'citations': [],\n",
    "                  'result_quality':[]}\n",
    "measurement_dict = {'specimen': [],'method_codes': [],'dir_dec': [],'dir_inc': [],'magn_volume': [], 'experiment': [],\n",
    "                    'dir_csd': [],'treat_temp':[], 'meas_temp': [],'treat_ac_field': [], 'treat_dc_field': [],'citations': [],\n",
    "                     'treat_dc_field_phi': [],'instrument_codes': [],'sequence':[], 'magn_moment': [], 'measurement': [],\n",
    "                    'treat_dc_field_theta': [],'treat_step_num':[],'quality': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f48bccc",
   "metadata": {},
   "source": [
    "### Cryo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell once for each file that you want to have in a location\n",
    "# when done, skip to the very last cell that writes magic files\n",
    "# .dat and .az files have to be in the same directory!! the name of the .az file has to agree with the one specified in the .dat file!\n",
    "\n",
    "file_path = r'G:\\My Drive\\__Postdoc\\Misc\\Side_quests\\UF2MagIC/22Deccan_Thermal-Master.dat' #path + file name\n",
    "\n",
    "treatment = 'both' # 'THD', 'AFD', or both' for directions; 'IZZI' for izzi pints (more to be added when needed)\n",
    "min_THD_step = 100 # only used if treatment = 'both'\n",
    "\n",
    "DC_field = 60 # uT value for the used lab field in intensity experiments\n",
    "DC_phi = 0 # 'declination' of applied field \n",
    "DC_theta = 90 # 'inclination' of applied field \n",
    "\n",
    "site_delimiter = '-' # e.g., '-' for MAT1-1.2 ([site]-[sample].[specimen]); if there is none, use ''\n",
    "site_chars = 3 # number of characters at the beginning of the sample name that are the site identifier. only used if \n",
    "               # site_delimiter = ''\n",
    "specimen_delimiter = '' # e.g., '.' for MAT1-1.2 ([site]-[sample].[specimen]); if specimen = sample, use ''\n",
    "specimen_chars = 0 # number of characters from the end of the sample names if there is no delimiter (use 0 for spec = sample)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------\n",
    "\n",
    "f = open(file_path)\n",
    "data = f.read().splitlines()\n",
    "f.close\n",
    "temp_data, specs = [],[]\n",
    "if True: # remove line\n",
    "    for i in range(len(data)):\n",
    "        if i <= 4:\n",
    "            temp_data.append(data[i])\n",
    "        else:\n",
    "            line = data[i].split()\n",
    "            if line[0] in specs: continue\n",
    "            specs.append(line[0])\n",
    "            temp_data.append(data[i])\n",
    "            for j in range(i+1,len(data)):\n",
    "                line = data[j].split()\n",
    "                if line[0] == specs[-1]: \n",
    "                    temp_data.append(data[j])\n",
    "        #print(temp_data[-1])\n",
    "    if len(temp_data) == len(data):\n",
    "        data = temp_data\n",
    "    else: \n",
    "        print('Measurement data could not be sorted')\n",
    "        print(len(data),len(temp_data))\n",
    "                \n",
    "\n",
    "orientations = {'sample': [], 'azi': [], 'plunge': [], 'bed_dir': [], 'bed_dip': []}\n",
    "sequence, last_treatment = 0, -1\n",
    "for ii in range(len(data)):\n",
    "    line = data[ii].split()\n",
    "    if ii == 0:\n",
    "        f = open(file_path.strip(line[0])+line[-1])\n",
    "        orientations_raw = f.readlines()\n",
    "        f.close()\n",
    "        for o_line in orientations_raw:\n",
    "            o_line = o_line.split()\n",
    "            orientations['sample'].append(o_line[0])\n",
    "            orientations['azi'].append(o_line[1])\n",
    "            orientations['plunge'].append(o_line[2])\n",
    "            orientations['bed_dir'].append(o_line[3])\n",
    "            orientations['bed_dip'].append(o_line[4])\n",
    "        continue\n",
    "    elif ii < 5: continue\n",
    "    \n",
    "    if not site_delimiter == '':\n",
    "        site_name = line[0].split(site_delimiter)[0]\n",
    "    else:\n",
    "        site_name = line[0][:site_chars+1]\n",
    "    duplicate_site = False\n",
    "    if not site_name in sites_dict['site']: sites_dict['site'].append(site_name)\n",
    "    else: duplicate_site = True\n",
    "    if not duplicate_site: sites_dict['citations'].append('This study')\n",
    "    if treatment == 'THD': \n",
    "        if not duplicate_site: \n",
    "            sites_dict['method_codes'].append('LP-DIR-T')\n",
    "        else: \n",
    "            for j in range(len(sites_dict['site'])):\n",
    "                if sites_dict['site'] == site_name:\n",
    "                    if not 'LP-DIR-T' in sites_dict['method_codes'][j]:\n",
    "                        sites_dict['method_codes'][j] += ':LP-DIR-T'\n",
    "    elif treatment == 'AFD': \n",
    "        if not duplicate_site: \n",
    "            sites_dict['method_codes'].append('LP-DIR-AF')\n",
    "        else: \n",
    "            for j in range(len(sites_dict['site'])):\n",
    "                if sites_dict['site'] == site_name:\n",
    "                    if not 'LP-DIR-AF' in sites_dict['method_codes'][j]:\n",
    "                        sites_dict['method_codes'][j] += ':LP-DIR-AF'\n",
    "    elif treatment == 'both': \n",
    "        if not duplicate_site: \n",
    "            sites_dict['method_codes'].append('LP-DIR-AF:LP-DIR-T')\n",
    "        else: \n",
    "            for j in range(len(sites_dict['site'])):\n",
    "                if sites_dict['site'] == site_name:\n",
    "                    if not 'LP-DIR-AF' in sites_dict['method_codes'][j]:\n",
    "                        sites_dict['method_codes'][j] += ':LP-DIR-AF'\n",
    "                    if not 'LP-DIR-T' in sites_dict['method_codes'][j]:\n",
    "                        sites_dict['method_codes'][j] += ':LP-DIR-T'\n",
    "    elif treatment == 'IZZI': \n",
    "        if not duplicate_site: \n",
    "            sites_dict['method_codes'].append('LP-PI-TRM:LP-PI-BT-IZZI:LP-PI-ALT-PTRM')\n",
    "        else: \n",
    "            for j in range(len(sites_dict['site'])):\n",
    "                if sites_dict['site'] == site_name:\n",
    "                    if not 'LP-PI-BT-IZZI' in sites_dict['method_codes'][j]:\n",
    "                        sites_dict['method_codes'][j] += ':LP-PI-TRM:LP-PI-BT-IZZI:LP-PI-ALT-PTRM'\n",
    "    else: print('Currently, only THD (thermal demag - directions), AFD (AF demag - directions), both (combined AF+TH) and IZZI (izzi pint) are availabe options')\n",
    "    \n",
    "    name = line[0]\n",
    "    if not specimen_delimiter == '':      \n",
    "        sample_name = name.split(specimen_delimiter)[0]\n",
    "        specimen_name = name\n",
    "    else:       \n",
    "        if not specimen_chars == 0:\n",
    "            sample_name = name[:-specimen_chars]\n",
    "        else:\n",
    "            sample_name = name\n",
    "        specimen_name = name\n",
    "    \n",
    "    duplicate_sample = False\n",
    "    if not sample_name in samples_dict['sample']: samples_dict['sample'].append(sample_name)\n",
    "    else: duplicate_sample = True\n",
    "        \n",
    "    if not duplicate_sample: \n",
    "        samples_dict['site'].append(site_name)\n",
    "        samples_dict['citations'].append('This study')\n",
    "        samples_dict['result_quality'].append('g')\n",
    "    \n",
    "    duplicate_specimen = False\n",
    "    if not name in specimens_dict['specimen']:\n",
    "        specimens_dict['specimen'].append(name)\n",
    "        specimens_dict['sample'].append(sample_name)\n",
    "        specimens_dict['citations'].append('This study')\n",
    "        specimens_dict['result_quality'].append('g')\n",
    "    else: duplicate_specimen = True\n",
    "    \n",
    "    if treatment == 'THD': \n",
    "        if not duplicate_sample: samples_dict['method_codes'].append('LP-DIR-T')\n",
    "        else:\n",
    "            for j in range(len(samples_dict['sample'])):\n",
    "                if samples_dict['sample'][j] == sample_name:\n",
    "                    if not 'LP-DIR-T' in samples_dict['method_codes'][j]:\n",
    "                        samples_dict['method_codes'][j] += ':LP-DIR-T'\n",
    "        if not duplicate_specimen:\n",
    "            specimens_dict['method_codes'].append('LP-DIR-T')\n",
    "            specimens_dict['experiments'].append(name+'_'+'LP-DIR-T')\n",
    "    elif treatment == 'AFD': \n",
    "        if not duplicate_sample: samples_dict['method_codes'].append('LP-DIR-AF')\n",
    "        else:\n",
    "            for j in range(len(samples_dict['sample'])):\n",
    "                if samples_dict['sample'][j] == sample_name:\n",
    "                    if not 'LP-DIR-AF' in samples_dict['method_codes'][j]:\n",
    "                        samples_dict['method_codes'][j] += ':LP-DIR-AF'\n",
    "        if not duplicate_specimen:\n",
    "            specimens_dict['method_codes'].append('LP-DIR-AF')\n",
    "            specimens_dict['experiments'].append(name+'_'+'LP-DIR-AF')\n",
    "    elif treatment == 'both': \n",
    "        if not duplicate_sample: samples_dict['method_codes'].append('LP-DIR-AF:LP-DIR-T')\n",
    "        else:\n",
    "            for j in range(len(samples_dict['sample'])):\n",
    "                if samples_dict['sample'][j] == sample_name:\n",
    "                    if not 'LP-DIR-T' in samples_dict['method_codes'][j] and 'LP-DIR-AF' in samples_dict['method_codes'][j]:\n",
    "                        samples_dict['method_codes'][j] += ':LP-DIR-T'\n",
    "                    elif not 'LP-DIR-AF' in samples_dict['method_codes'][j] and 'LP-DIR-T' in samples_dict['method_codes'][j]:\n",
    "                        samples_dict['method_codes'][j] += ':LP-DIR-AF'\n",
    "                    elif not 'LP-DIR-AF:LP-DIR-T' in samples_dict['method_codes'][j] and  not 'LP-DIR-T:LP-DIR-AF' in samples_dict['method_codes'][j]:\n",
    "                        print(sample_name, samples_dict['method_codes'][j])\n",
    "                        samples_dict['method_codes'][j] += ':LP-DIR-AF:LP-DIR-T'\n",
    "                    break\n",
    "        if not duplicate_specimen:\n",
    "            specimens_dict['method_codes'].append('LP-DIR-AF:LP-DIR-T')\n",
    "            specimens_dict['experiments'].append(name+'_'+'LP-DIR-AFT')\n",
    "        \n",
    "    elif treatment == 'IZZI':\n",
    "        if not duplicate_sample: samples_dict['method_codes'].append('LP-PI-TRM:LP-PI-BT-IZZI:LP-PI-ALT-PTRM')\n",
    "        else:\n",
    "            for j in range(len(samples_dict['sample'])):\n",
    "                if samples_dict['sample'][j] == sample_name:\n",
    "                    if not 'LP-PI-BT-IZZI' in samples_dict['method_codes'][j]:\n",
    "                        samples_dict['method_codes'][j] += ':LP-PI-TRM:LP-PI-BT-IZZI:LP-PI-ALT-PTRM'\n",
    "        if not duplicate_specimen:\n",
    "            specimens_dict['method_codes'].append('LP-PI-TRM:LP-PI-BT-IZZI:LP-PI-ALT-PTRM')\n",
    "            specimens_dict['experiments'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "    \n",
    "    \n",
    "    \n",
    "    if not duplicate_sample:\n",
    "        for jj in range(len(orientations['sample'])):\n",
    "            if orientations['sample'][jj] == name:\n",
    "                samples_dict['azimuth'].append(str(orientations['azi'][jj]))\n",
    "                samples_dict['dip'].append(str((float(orientations['plunge'][jj])-90)))\n",
    "\n",
    "                samples_dict['bed_dip_direction'].append(str(orientations['bed_dir'][jj]))\n",
    "                samples_dict['bed_dip'].append(str(orientations['bed_dip'][jj]))\n",
    "                break\n",
    "        if not len(samples_dict['sample']) == len(samples_dict['bed_dip']):\n",
    "            print('Could not find orientation data for ', name)\n",
    "            samples_dict['azimuth'].append('')\n",
    "            samples_dict['dip'].append('') #check orientation\n",
    "            samples_dict['bed_dip_direction'].append('')\n",
    "            samples_dict['bed_dip'].append('')\n",
    "    \n",
    "    treat = float(line[1])\n",
    "    volume = 10 * 10**-6    #  10 cc assumed by cryo to m2                                     \n",
    "    if not duplicate_specimen: specimens_dict['volume'].append(str(volume)) # m^3\n",
    "      \n",
    "    measurement_dict['specimen'].append(name)\n",
    "    \n",
    "    if treat > last_treatment and not treatment == 'IZZI': sequence += 1\n",
    "    elif treatment == 'IZZI': \n",
    "        sequence += 1\n",
    "        if sequence > 1 and not measurement_dict['specimen'][-1] == measurement_dict['specimen'][-2]: sequence = 0\n",
    "    if sequence < 10: seq_str = '0'+str(sequence)\n",
    "    else: seq_str = str(sequence)\n",
    "    measurement_dict['sequence'].append(str(seq_str))\n",
    "    measurement_dict['citations'].append('This study')\n",
    "    \n",
    "    if sequence == 1: measurement_dict['quality'].append('g')\n",
    "    else:\n",
    "        if not treatment == 'IZZI':\n",
    "            if treat == last_treatment: # attempting to catch repeat measurements\n",
    "                #print(treat,last_treatment)\n",
    "                measurement_dict['quality'][-1] = 'b' # assumes that the first one was bad\n",
    "        measurement_dict['quality'].append('g')\n",
    "                                             \n",
    "    if treatment == 'THD':\n",
    "        measurement_dict['treat_temp'].append(str(float(treat)+273)) # K\n",
    "        measurement_dict['meas_temp'].append(str(273)) # K\n",
    "        measurement_dict['treat_ac_field'].append(str(0)) # T\n",
    "        measurement_dict['treat_dc_field'].append(str(0)) # T\n",
    "        measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "        measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "        measurement_dict['method_codes'].append('LT-T-Z')\n",
    "        measurement_dict['experiment'].append(name+'_'+'LP-DIR-T')\n",
    "        measurement_dict['measurement'].append(name+'_'+'LP-DIR-T'+'-'+str(seq_str))\n",
    "                    \n",
    "    elif treatment == 'AFD':\n",
    "        measurement_dict['treat_temp'].append(str(273)) # K\n",
    "        measurement_dict['meas_temp'].append(str(273)) # K\n",
    "        measurement_dict['treat_ac_field'].append(str(float(treat)/10**3)) # T\n",
    "        measurement_dict['treat_dc_field'].append(str(0)) # T\n",
    "        measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "        measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "        measurement_dict['method_codes'].append('LT-AF-Z')\n",
    "        measurement_dict['experiment'].append(name+'_'+'LP-DIR-AF')\n",
    "        measurement_dict['measurement'].append(name+'_'+'LP-DIR-AF'+'-'+str(seq_str))\n",
    "    \n",
    "    elif treatment == 'both':\n",
    "        if treat < min_THD_step:\n",
    "            measurement_dict['treat_temp'].append(str(273)) # K\n",
    "            measurement_dict['meas_temp'].append(str(273)) # K\n",
    "            measurement_dict['treat_ac_field'].append(str(float(treat)/10**3)) # T\n",
    "            measurement_dict['treat_dc_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "            measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "            measurement_dict['method_codes'].append('LT-AF-Z')\n",
    "            measurement_dict['experiment'].append(name+'_'+'LP-DIR-AFT')\n",
    "            measurement_dict['measurement'].append(name+'_'+'LP-DIR-AFT'+'-'+str(seq_str))\n",
    "        else:\n",
    "            measurement_dict['treat_temp'].append(str(float(treat)+273)) # K\n",
    "            measurement_dict['meas_temp'].append(str(273)) # K\n",
    "            measurement_dict['treat_ac_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_dc_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "            measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "            measurement_dict['method_codes'].append('LT-T-Z')\n",
    "            measurement_dict['experiment'].append(name+'_'+'LP-DIR-AFT')\n",
    "            measurement_dict['measurement'].append(name+'_'+'LP-DIR-AFT'+'-'+str(seq_str))\n",
    "            \n",
    "    if treatment == 'IZZI':\n",
    "        if str(treat)[-2:] == '.0': # Z\n",
    "            measurement_dict['treat_temp'].append(str(float(str(treat)[:-2])+273)) # K\n",
    "            measurement_dict['meas_temp'].append(str(273)) # K\n",
    "            measurement_dict['treat_dc_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_ac_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "            measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "            if treat == 0:\n",
    "                measurement_dict['method_codes'].append('LT-NO:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            else:\n",
    "                if 'LT-NO' in measurement_dict['method_codes'][-1] or 'LT-PTRM-I' in measurement_dict['method_codes'][-1] \\\n",
    "                or ('LT-T-Z' in measurement_dict['method_codes'][-1] and 'LP-PI-TRM-IZ' in measurement_dict['method_codes'][-1]):\n",
    "                    measurement_dict['method_codes'].append('LT-T-Z:LP-PI-TRM-ZI:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "                else:\n",
    "                    measurement_dict['method_codes'].append('LT-T-Z:LP-PI-TRM-IZ:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            measurement_dict['experiment'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement_dict['measurement'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        elif str(treat)[-2:] == '.1': # I\n",
    "            measurement_dict['treat_temp'].append(str(float(str(treat)[:-2])+273)) # K\n",
    "            measurement_dict['meas_temp'].append(str(273)) # K\n",
    "            measurement_dict['treat_dc_field'].append(str(DC_field*10**-6)) # T\n",
    "            measurement_dict['treat_ac_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "            measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "            if 'LT-PTRM-I' in measurement_dict['method_codes'][-1] \\\n",
    "                or ('LT-T-Z' in measurement_dict['method_codes'][-1] and 'LP-PI-TRM-ZI' in measurement_dict['method_codes'][-1]):\n",
    "                measurement_dict['method_codes'].append('LT-T-I:LP-PI-TRM-ZI:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            else:\n",
    "                measurement_dict['method_codes'].append('LT-T-I:LP-PI-TRM-IZ:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            measurement_dict['experiment'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement_dict['measurement'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        elif str(treat)[-2:] == '.2': # P\n",
    "            measurement_dict['treat_temp'].append(str(float(str(treat)[:-2])+273)) # K\n",
    "            measurement_dict['meas_temp'].append(str(273)) # K\n",
    "            measurement_dict['treat_dc_field'].append(str(DC_field*10**-6)) # T\n",
    "            measurement_dict['treat_ac_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "            measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "            measurement_dict['method_codes'].append('LT-PTRM-I:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            measurement_dict['experiment'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement_dict['measurement'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        elif str(treat)[-2:] == '.3': # T\n",
    "            measurement_dict['treat_temp'].append(str(float(str(treat)[:-2])+273)) # K\n",
    "            measurement_dict['meas_temp'].append(str(273)) # K\n",
    "            measurement_dict['treat_dc_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_ac_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "            measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "            measurement_dict['method_codes'].append('LT-PTRM-Z:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            measurement_dict['experiment'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement_dict['measurement'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        elif str(treat)[-2:] == '.4': # A\n",
    "            measurement_dict['treat_temp'].append(str(float(str(treat)[:-2])+273)) # K\n",
    "            measurement_dict['meas_temp'].append(str(273)) # K\n",
    "            measurement_dict['treat_dc_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_ac_field'].append(str(0)) # T\n",
    "            measurement_dict['treat_dc_field_phi'].append(str(0)) # deg\n",
    "            measurement_dict['treat_dc_field_theta'].append(str(0)) # deg\n",
    "            measurement_dict['method_codes'].append('LT-PTRM-AC:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            measurement_dict['experiment'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement_dict['measurement'].append(name+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        \n",
    "    intensity = float(line[4])*25/np.pi # Oe => Oe * 20/pi = A/m \n",
    "    measurement_dict['magn_volume'].append(str(float(intensity))) # A/m\n",
    "    measurement_dict['magn_moment'].append(str((float(intensity))*(float(volume))))#/10**6))) # Am^2\n",
    "    GDec = (line[7]) # not needed for demag GUI\n",
    "    GInc = (line[8]) # not needed for demag GUI\n",
    "    csd = line[3] # not sure if this is actually csd or something else\n",
    "    measurement_dict['dir_csd'].append(csd)\n",
    "    CDec = line[5]\n",
    "    measurement_dict['dir_dec'].append(CDec)\n",
    "    CInc = line[6]\n",
    "    measurement_dict['dir_inc'].append(CInc)\n",
    "    measurement_dict['instrument_codes'].append('Cryo')\n",
    "    measurement_dict['treat_step_num'].append(str(int(seq_str)+1))\n",
    "    last_treatment = treat\n",
    "    \n",
    "print('Done!')\n",
    "\n",
    "#for key in samples_dict.keys():\n",
    "#    print(key,len(samples_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80aea2",
   "metadata": {},
   "source": [
    "### Molspin data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add measurement data for a site \n",
    "# run this cell once for each directory specified below. Use one directory per site & experiment\n",
    "#assumes that specimen == sample\n",
    "\n",
    "site_name = 'I1938' # Specify name of site\n",
    "treatment = 'THD' # Specify if the experiment was thermal demag ('THD') or AF demag ('AFD')\n",
    "site_dir_path = r'G:\\My Drive\\__Postdoc\\Misc\\Side_quests\\UF2MagIC\\I1938' # absolute or relative path to directory \n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "duplicate_site = False\n",
    "if not site_name in sites_dict['site']: sites_dict['site'].append(site_name)\n",
    "else: duplicate_site = True\n",
    "if not duplicate_site: sites_dict['citations'].append('This study')\n",
    "if treatment == 'THD': \n",
    "    if not duplicate_site: \n",
    "        sites_dict['method_codes'].append('LP-DIR-T')\n",
    "    else: \n",
    "        for j in range(len(sites_dict['site'])):\n",
    "            if sites_dict['site'] == site_name:\n",
    "                if not 'LP-DIR-T' in sites_dict['method_codes'][j]:\n",
    "                    sites_dict['method_codes'][j] += ':LP-DIR-T'\n",
    "elif treatment == 'AFD': \n",
    "    if not duplicate_site: \n",
    "        sites_dict['method_codes'].append('LP-DIR-AF')\n",
    "    else: \n",
    "        for j in range(len(sites_dict['site'])):\n",
    "            if sites_dict['site'] == site_name:\n",
    "                if not 'LP-DIR-AF' in sites_dict['method_codes'][j]:\n",
    "                    sites_dict['method_codes'][j] += ':LP-DIR-AF'\n",
    "else: print('Currently, only THD (thermal demag - directions) or AFD (AF demag - directions) are availabe options')\n",
    "\n",
    "if not site_dir_path.endswith('/'): site_dir_path += '/'\n",
    "for root, dirs, files in os.walk(site_dir_path): \n",
    "    for file in files:\n",
    "        with open(root+os.sep+file) as specimen_file:\n",
    "            measurement_data = specimen_file.readlines()\n",
    "        sequence, last_treat = 0, -1\n",
    "        for i in range(len(measurement_data)):\n",
    "            measurement_data[i] = measurement_data[i].strip('\\n')\n",
    "            if i == 0:\n",
    "                samples_dict['site'].append(site_name)\n",
    "                samples_dict['citations'].append('This study')\n",
    "                samples_dict['result_quality'].append('g')\n",
    "                specimens_dict['citations'].append('This study')\n",
    "                specimens_dict['result_quality'].append('g')\n",
    "                header = measurement_data[i].split()\n",
    "                name = header[0]\n",
    "                if treatment == 'THD': \n",
    "                    samples_dict['method_codes'].append('LP-DIR-T')\n",
    "                    specimens_dict['method_codes'].append('LP-DIR-T')\n",
    "                    specimens_dict['experiments'].append(name+'_'+'LP-DIR-T')\n",
    "                elif treatment == 'AFD': \n",
    "                    samples_dict['method_codes'].append('LP-DIR-AF')\n",
    "                    specimens_dict['method_codes'].append('LP-DIR-AF')\n",
    "                    specimens_dict['experiments'].append(name+'_'+'LP-DIR-AF')\n",
    "                samples_dict['sample'].append(name)\n",
    "                specimens_dict['sample'].append(name)\n",
    "                specimens_dict['specimen'].append(name)\n",
    "                bearing = header[1]\n",
    "                samples_dict['azimuth'].append(bearing)\n",
    "                plunge = header[2]\n",
    "                samples_dict['dip'].append(str(float(plunge)-90))\n",
    "                strike = header[3]\n",
    "                samples_dict['bed_dip_direction'].append(str(float(strike)+90))\n",
    "                dip = header[4]\n",
    "                samples_dict['bed_dip'].append(dip)\n",
    "                volume = header[5]\n",
    "                specimens_dict['volume'].append(str(float(volume)/10**6)) # m^3\n",
    "            else:\n",
    "                measurement = measurement_data[i].split()\n",
    "                measurement_dict['citations'].append('This study')\n",
    "                measurement_dict['specimen'].append(name)\n",
    "                treat = int(measurement[0])\n",
    "                if treatment == 'THD':\n",
    "                    measurement_dict['treat_temp'].append(str(float(treat)+273)) # K\n",
    "                    measurement_dict['meas_temp'].append(str(273)) # K\n",
    "                    measurement_dict['treat_ac_field'].append(str(0)) # T\n",
    "                    measurement_dict['method_codes'].append('LT-T-Z')\n",
    "                    measurement_dict['experiment'].append(name+'_'+'LP-DIR-T')\n",
    "                    measurement_dict['measurement'].append(name+'_'+'LP-DIR-T'+'-'+str(i))\n",
    "                    \n",
    "                elif treatment == 'AFD':\n",
    "                    measurement_dict['treat_temp'].append(str(273)) # K\n",
    "                    measurement_dict['meas_temp'].append(str(273)) # K\n",
    "                    measurement_dict['treat_ac_field'].append(str(float(treat)/10**3)) # T\n",
    "                    measurement_dict['method_codes'].append('LT-AF-Z')\n",
    "                    measurement_dict['experiment'].append(name+'_'+'LP-DIR-AF')\n",
    "                    measurement_dict['measurement'].append(name+'_'+'LP-DIR-AF'+'-'+str(i))\n",
    "\n",
    "                if treat > last_treat: sequence += 1\n",
    "                if sequence == 1:\n",
    "                    measurement_dict['quality'].append('g')\n",
    "                else:\n",
    "                        if not treat > last_treat: # attempting to catch repeat measurements\n",
    "                            measurement_dict['quality'][-1] = 'b' # assumes that the first one was bad\n",
    "                        measurement_dict['quality'].append('g')\n",
    "                    \n",
    "                if sequence < 10: seq_str = '0'+str(sequence)\n",
    "                else: seq_str = str(sequence)\n",
    "                measurement_dict['sequence'].append(seq_str)\n",
    "                intensity = measurement[1] # mA/m\n",
    "                measurement_dict['magn_volume'].append(str(float(intensity)/10**3)) # A/m\n",
    "                measurement_dict['magn_moment'].append(str((float(intensity)/10**3)*(float(volume)/10**6))) # Am^2\n",
    "                GDec = (measurement[2]) # not needed for demag GUI\n",
    "                GInc = (measurement[3]) # not needed for demag GUI\n",
    "                a95 = measurement[4]\n",
    "                measurement_dict['dir_csd'].append(a95)\n",
    "                CDec = measurement[5]\n",
    "                measurement_dict['dir_dec'].append(CDec)\n",
    "                CInc = measurement[6]\n",
    "                measurement_dict['dir_inc'].append(CInc)\n",
    "                measurement_dict['instrument_codes'].append('Molspin')\n",
    "                measurement_dict['treat_dc_field'].append(0)\n",
    "                measurement_dict['treat_dc_field_theta'].append(0)\n",
    "                measurement_dict['treat_dc_field_phi'].append(0)\n",
    "                measurement_dict['treat_step_num'].append(seq_str)\n",
    "\n",
    "print('Specimens for site', site_name, 'added successfully')\n",
    "#for key in measurement_dict.keys():\n",
    "#    print(key,len(measurement_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbcc43b",
   "metadata": {},
   "source": [
    "## JR6 data\n",
    "\n",
    "convert jr6 data to magic format. Experimental. Agico orientation parameters are not considered at the moment. Use with caution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d74f32e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path = r'G:\\My Drive\\__Postdoc\\Misc\\Side_quests\\UF2MagIC' #os.getcwd()\n",
    "file = 'test_data.jr6'\n",
    "volume = 7 #cc\n",
    "\n",
    "protocol = 'Dir' # 'PTSD' 'Dir'\n",
    "# for pseuro-Thellier and Shaw experiments: ARM demag series have to have .01 as identifier in AF field\n",
    "\n",
    "DC_field = 60 # uT value for the used lab field in intensity experiments\n",
    "DC_phi = 0 # 'declination' of applied field \n",
    "DC_theta = 90 # 'inclination' of applied field \n",
    "\n",
    "site_delimiter = '-' # e.g., '-' for MAT1-1.2 ([site]-[sample].[specimen]); if there is none, use ''\n",
    "site_chars = 2 # number of characters at the beginning of the sample name that are the site identifier. only used if \n",
    "               # site_delimiter = ''\n",
    "specimen_delimiter = '' # e.g., '.' for MAT1-1.2 ([site]-[sample].[specimen]); if specimen = sample, use ''\n",
    "specimen_chars = 1 # number of characters from the end of the sample names if there is no delimiter (use 0 for spec = sample)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "if not path.endswith('/'): path += '/'\n",
    "f=open(path+file)\n",
    "tempdata=f.readlines()\n",
    "f.close()\n",
    "tempfile = open('temp.txt','w')\n",
    "tempfile.close()\n",
    "for line in tempdata:\n",
    "    line = line[:9].strip(' ') + line[9:].replace('-',',-').replace(' ',',').replace('\\t',',')\n",
    "    while ',,' in line:\n",
    "        line=line.replace(',,',',')\n",
    "    with open('temp.txt','a') as tempfile:\n",
    "        tempfile.write(line)\n",
    "jr6_raw = pd.read_csv('temp.txt',sep=\",\",header=None,names=['specimen','treat','m_x','m_y','m_z','exp','azimuth','spec_plunge',\n",
    "                                                            'tect_azi','tect_plunge','bed_dip_direction','bed_plunge','orient_1',\n",
    "                                                            'orient_2','orient_3','orient_4','csd'])\n",
    "os.remove('temp.txt')\n",
    "jr6_raw['m_x'] = (jr6_raw['m_x'].astype(str)+'E'+jr6_raw['exp'].astype(str)).astype(float)\n",
    "jr6_raw['m_y'] = (jr6_raw['m_y'].astype(str)+'E'+jr6_raw['exp'].astype(str)).astype(float)\n",
    "jr6_raw['m_z'] = (jr6_raw['m_z'].astype(str)+'E'+jr6_raw['exp'].astype(str)).astype(float)\n",
    "jr6_raw['magn_volume'] = np.sqrt(jr6_raw['m_x']**2 + jr6_raw['m_y']**2 + jr6_raw['m_z']**2) # A/m\n",
    "jr6_raw['magn_moment'] = jr6_raw['magn_volume']*(float(volume)/10**6) # Am2\n",
    "jr6_raw['dir_dec'] = round((np.arctan2(jr6_raw['m_y'],jr6_raw['m_x'])*180/np.pi)%360,2)\n",
    "jr6_raw['dir_inc'] = round((np.arctan2(jr6_raw['m_z'],np.sqrt(jr6_raw['m_x']**2+jr6_raw['m_y']**2)) *180/np.pi),2) # A/m\n",
    "#print(jr6_raw)\n",
    "if not sum(jr6_raw['tect_azi']) == 0 and not sum(jr6_raw['tect_plunge']) == 0: \n",
    "    samples_dict['tect_azi'] = []\n",
    "    samples_dict['tect_plunge'] = []\n",
    "jr6_raw['dir_csd'] = np.zeros(len(jr6_raw))\n",
    "jr6_raw['meas_temp'] = np.ones(len(jr6_raw))*273\n",
    "jr6_raw['volume'] = np.ones(len(jr6_raw))*float(volume)/10**6\n",
    "jr6_raw['dip'] = jr6_raw['spec_plunge']-90\n",
    "jr6_raw['instrument_codes'] = 'JR6'\n",
    "jr6_raw['quality'] = 'g'\n",
    "jr6_raw['result_quality'] = 'g'\n",
    "jr6_raw['citations'] = 'This study'\n",
    "jr6_raw['bed_dip'] = jr6_raw['bed_plunge']#-90\n",
    "jr6_raw['treat_dc_field'] = np.zeros(len(jr6_raw))#np.ones(len(jr6_raw)) * DC_field *10**-6\n",
    "jr6_raw['treat_dc_field_phi'] = np.zeros(len(jr6_raw))#np.ones(len(jr6_raw)) * DC_phi\n",
    "jr6_raw['treat_dc_field_theta'] = np.zeros(len(jr6_raw))#np.ones(len(jr6_raw)) * DC_theta\n",
    "\n",
    "jr6_raw['index'] = jr6_raw.index\n",
    "jr6_raw = jr6_raw.sort_values(by=['specimen','index'])\n",
    "site, sample, method_code, treat_ac_field, experiment,treat_temp, measurement = [],[],[],[],[],[],[]\n",
    "sequence, treat_step_num = [],[]\n",
    "if not protocol == 'Dir': treat_dc_field, treat_dc_field_phi, treat_dc_field_theta = [],[],[]\n",
    "lastname = ''\n",
    "for i in range(len(jr6_raw)):\n",
    "    if i == 0: lastname = jr6_raw.loc[jr6_raw.index[i],'specimen']\n",
    "    if not site_delimiter == '': \n",
    "        site.append(jr6_raw.loc[jr6_raw.index[i],'specimen'].split(site_delimiter)[0])\n",
    "    else: \n",
    "        site.append(jr6_raw.loc[jr6_raw.index[i],'specimen'][:site_chars+1])\n",
    "                       \n",
    "    if not specimen_delimiter == '': sample.append(''.join(jr6_raw.loc[jr6_raw.index[i],'specimen'].split(site_delimiter)[:-1]))\n",
    "    else:\n",
    "        if not specimen_chars == 0:\n",
    "            sample.append(jr6_raw.loc[jr6_raw.index[i],'specimen'][:-specimen_chars])\n",
    "        else:\n",
    "            sample.append(jr6_raw.loc[jr6_raw.index[i],'specimen'])\n",
    "            \n",
    "    if i > 0 and lastname == jr6_raw.loc[jr6_raw.index[i],'specimen']:\n",
    "        sequence.append(int(sequence[-1])+1)\n",
    "    else:\n",
    "        sequence.append(0)\n",
    "    if sequence[-1] < 10: seq_str = '00'+str(sequence[-1])\n",
    "    elif i < 100: seq_str = '0'+str(sequence[-1])\n",
    "    else: seq_str = str(sequence[-1])\n",
    "    treat_step_num.append(int(seq_str))\n",
    "    sequence[-1] = seq_str\n",
    "                        \n",
    "    if protocol == 'Dir':\n",
    "        if 'NRM' in jr6_raw.loc[jr6_raw.index[i],'treat']:\n",
    "            method_code.append('LT-AF-Z') \n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-AF') \n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-AF'+'-'+str(i)) \n",
    "            treat_temp.append(273)\n",
    "            treat_ac_field.append(0)\n",
    "            #check for double NRM steps\n",
    "            if i < len(jr6_raw):\n",
    "                if 'NRM' in jr6_raw.loc[jr6_raw.index[i+1],'treat']:\n",
    "                    for j in range(i,len(jr6_raw)):\n",
    "                        if not 'NRM' in jr6_raw.loc[jr6_raw.index[j],'treat']:\n",
    "                            if 'TD' in jr6_raw.loc[jr6_raw.index[j],'treat']:\n",
    "                                method_code[-1] = 'LT-T-Z'\n",
    "                                experiment[-1] = str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-T'\n",
    "                                measurement[-1] = str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-T'+'-'+str(i)\n",
    "                                break\n",
    "                            elif 'AD' in jr6_raw.loc[jr6_raw.index[j],'treat']:\n",
    "                                break\n",
    "        if 'AD' in jr6_raw.loc[jr6_raw.index[i],'treat']: \n",
    "            method_code.append('LT-AF-Z')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-AF')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-AF'+'-'+str(i))\n",
    "            treat_temp.append(273)\n",
    "            treat_ac_field.append(float(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('AD'))*10**-3)\n",
    "        elif 'TD' in jr6_raw.loc[jr6_raw.index[i],'treat']: \n",
    "            method_code.append('LT-T-Z')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-T')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-T'+'-'+str(i))\n",
    "            treat_temp.append(float(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('TD'))+273)\n",
    "            treat_ac_field.append(0)\n",
    "            if 'NRM' in jr6_raw.loc[jr6_raw.index[i-1],'treat']:\n",
    "                method_code[-2] = 'LT-T-Z'\n",
    "                experiment[-2] = str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-T'\n",
    "                measurement[-2] = str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-DIR-T'+'-'+str(i)\n",
    "    elif protocol == 'PTSD':\n",
    "        if 'NRM' in jr6_raw.loc[jr6_raw.index[i],'treat']: \n",
    "            method_code.append('LT-NO:LP-DIR-AF:LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM'+'-'+str(i))\n",
    "            treat_temp.append(273)\n",
    "            treat_ac_field.append(0)\n",
    "            treat_dc_field.append(str(0*DC_field*10**-6))\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "        if 'AD' in jr6_raw.loc[jr6_raw.index[i],'treat']: \n",
    "            if not jr6_raw.loc[jr6_raw.index[i],'treat'].endswith('.01'):\n",
    "                method_code.append('LT-AF-Z:LP-DIR-AF:LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "                treat_temp.append(273)\n",
    "                treat_ac_field.append(float(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('AD'))*10**-3)\n",
    "                experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "                measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM'+'-'+str(i))\n",
    "                treat_dc_field.append(str(0*DC_field*10**-6))\n",
    "                treat_dc_field_phi.append(str(DC_phi))\n",
    "                treat_dc_field_theta.append(str(DC_theta))\n",
    "            else:\n",
    "                method_code.append('LT-AF-Z:LP-ARM-AFD:LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "                treat_temp.append(273)\n",
    "                treat_ac_field.append(float(jr6_raw.loc[jr6_raw.index[i],'treat'][:-1].strip('AD'))*10**-3)\n",
    "                experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "                measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM'+'-'+str(i))\n",
    "                treat_dc_field.append(str(0*DC_field*10**-6))\n",
    "                treat_dc_field_phi.append(str(DC_phi))\n",
    "                treat_dc_field_theta.append(str(DC_theta))\n",
    "\n",
    "        elif 'TD' in jr6_raw.loc[jr6_raw.index[i],'treat']: \n",
    "            method_code.append('LT-T-I:LP-TRM-AFD:LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "            treat_temp.append(float(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('TD'))+273)\n",
    "            treat_ac_field.append(0)\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM'+'-'+str(i))\n",
    "            treat_dc_field.append(str(DC_field*10**-6))\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "        elif 'ARM' in jr6_raw.loc[jr6_raw.index[i],'treat']: \n",
    "            method_code.append('LT-AF-I:LP-ARM-AFD:LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "            treat_temp.append(273)\n",
    "            treat_ac_field.append(float(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('ARM'))*10**-3)\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM:LP-PI-ARM:LP-PI-ALT-AFARM'+'-'+str(i))\n",
    "            treat_dc_field.append(str(0*DC_field*10**-6))\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "    elif protocol == 'IZZI':\n",
    "        #print(jr6_raw.loc[jr6_raw.index[i],'treat'])\n",
    "        if 'NRM' in jr6_raw.loc[jr6_raw.index[i],'treat']: \n",
    "            method_code.append('LT-NO:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(i))\n",
    "            treat_temp.append(273)\n",
    "            treat_ac_field.append(0)\n",
    "            treat_dc_field.append(str(0*DC_field*10**-6))\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "        elif str(jr6_raw.loc[jr6_raw.index[i],'treat'])[-2:] == '.0': # Z\n",
    "            treat_temp.append(str(float(str(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('TD'))[:-2])+273)) # K\n",
    "            treat_dc_field.append(str(0*DC_field*10**-6))\n",
    "            treat_ac_field.append(str(0)) # T\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "            if 'LT-NO' in method_code[-1] or 'LT-PTRM-I' in method_code[-1] \\\n",
    "                or ('LT-T-Z' in method_code[-1] and 'LP-PI-TRM-IZ' in method_code[-1]):\n",
    "                    method_code.append('LT-T-Z:LP-PI-TRM-ZI:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            else:\n",
    "                    method_code.append('LT-T-Z:LP-PI-TRM-IZ:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        elif str(jr6_raw.loc[jr6_raw.index[i],'treat'])[-2:] == '.1': # I\n",
    "            treat_temp.append(str(float(str(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('TD'))[:-2])+273)) # K\n",
    "            treat_dc_field.append(str(DC_field*10**-6))\n",
    "            treat_ac_field.append(str(0)) # T\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "            if 'LT-PTRM-I' in method_code[-1] \\\n",
    "                or ('LT-T-Z' in method_code[-1] and 'LP-PI-TRM-ZI' in method_code[-1]):\n",
    "                method_code.append('LT-T-I:LP-PI-TRM-ZI:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            else:\n",
    "                method_code.append('LT-T-I:LP-PI-TRM-IZ:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        elif str(jr6_raw.loc[jr6_raw.index[i],'treat'])[-2:] == '.2': # P\n",
    "            treat_temp.append(str(float(str(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('TD'))[:-2])+273)) # K\n",
    "            treat_dc_field.append(str(DC_field*10**-6))\n",
    "            treat_ac_field.append(str(0)) # T\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "            method_code.append('LT-PTRM-I:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        elif str(jr6_raw.loc[jr6_raw.index[i],'treat'])[-2:] == '.3': # T\n",
    "            treat_temp.append(str(float(str(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('TD'))[:-2])+273)) # K\n",
    "            treat_dc_field.append(str(0*DC_field*10**-6))\n",
    "            treat_ac_field.append(str(0)) # T\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "            method_code.append('LT-PTRM-Z:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "        elif str(jr6_raw.loc[jr6_raw.index[i],'treat'])[-2:] == '.4': # A\n",
    "            treat_temp.append(str(float(str(jr6_raw.loc[jr6_raw.index[i],'treat'].strip('TD'))[:-2])+273)) # K\n",
    "            treat_dc_field.append(str(0*DC_field*10**-6))\n",
    "            treat_ac_field.append(str(0)) # T\n",
    "            treat_dc_field_phi.append(str(DC_phi))\n",
    "            treat_dc_field_theta.append(str(DC_theta))\n",
    "            method_code.append('LT-PTRM-AC:LP-PI-TRM:LP-PI-ALT-PTRM:LP-PI-BT-IZZI')\n",
    "            experiment.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI')\n",
    "            measurement.append(str(jr6_raw.loc[jr6_raw.index[i],'specimen'])+'_'+'LP-PI-TRM_LP-PI-ALT-PTRM_LP-PI-BT-IZZI'+'-'+str(seq_str))\n",
    "    else:\n",
    "        print('protocol has not been added yet. contact whoever is responsible for this notebook')\n",
    "    lastname = jr6_raw.loc[jr6_raw.index[i],'specimen']    \n",
    "jr6_raw['site'] = site\n",
    "jr6_raw['sample'] = sample\n",
    "jr6_raw['method_codes'] = method_code\n",
    "jr6_raw['experiment'] = experiment\n",
    "jr6_raw['measurement'] = measurement\n",
    "jr6_raw['sequence'] = sequence\n",
    "jr6_raw['treat_step_num'] = treat_step_num\n",
    "jr6_raw['treat_temp'] = treat_temp\n",
    "jr6_raw['treat_ac_field'] = treat_ac_field\n",
    "if not protocol == 'Dir':\n",
    "    jr6_raw['treat_dc_field'] = treat_dc_field\n",
    "    jr6_raw['treat_dc_field_phi'] = treat_dc_field_phi\n",
    "    jr6_raw['treat_dc_field_theta'] = treat_dc_field_theta\n",
    "                                                   \n",
    "sites_new = list(set(jr6_raw['site']))\n",
    "for i in range(len(sites_new)):\n",
    "    if not sites_new[i] in sites_dict['site']:\n",
    "        sites_dict['site'].append(sites_new[i])\n",
    "for i in range(len(sites_dict['site'])):\n",
    "    temp_df = jr6_raw[jr6_raw['site'] == sites_dict['site'][i]]\n",
    "    if not len(temp_df) == 0:\n",
    "        sites_dict['method_codes'].append(':'.join(list(set(temp_df['method_codes'].astype(str)))))\n",
    "        sites_dict['citations'].append(':'.join(list(set(temp_df['citations'].astype(str)))))\n",
    "samples_new = list(set(jr6_raw['sample']))\n",
    "for i in range(len(samples_new)):\n",
    "    if not samples_new[i] in samples_dict:\n",
    "        samples_dict['sample'].append(samples_new[i])\n",
    "for i in range(len(samples_dict['sample'])):\n",
    "    temp_df = jr6_raw[jr6_raw['sample'] == samples_dict['sample'][i]]\n",
    "    if not len(temp_df) == 0:\n",
    "        for key in samples_dict.keys():\n",
    "            if not key == 'sample':\n",
    "                samples_dict[key].append(':'.join(list(set(temp_df[key].astype(str)))))\n",
    "specimens_new = list(set(jr6_raw['specimen']))\n",
    "for i in range(len(specimens_new)):\n",
    "    if not specimens_new[i] in specimens_dict:\n",
    "        specimens_dict['specimen'].append(specimens_new[i])\n",
    "for i in range(len(specimens_dict['specimen'])):\n",
    "    temp_df = jr6_raw[jr6_raw['specimen'] == specimens_dict['specimen'][i]]\n",
    "    if not len(temp_df) == 0:\n",
    "        for key in specimens_dict.keys():\n",
    "            if key == 'experiments':\n",
    "                specimens_dict[key].append(':'.join(list(set(temp_df['experiment'].astype(str)))))\n",
    "            elif not key == 'specimen':\n",
    "                specimens_dict[key].append(':'.join(list(set(temp_df[key].astype(str)))))\n",
    "\n",
    "for key in measurement_dict.keys():\n",
    "    measurement_dict[key] = jr6_raw[key].values\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979989a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell only exists to find issues with the notebook\n",
    "for key in measurement_dict.keys():\n",
    "    print(measurement_dict[key], len(measurement_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7f95d",
   "metadata": {},
   "source": [
    "### Write MagIC formatted files\n",
    "\n",
    "Run cell after all experiments of the current location have been added using the cell above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c3f470a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files for pmagpy GUI saved to G:\\My Drive\\__Postdoc\\Misc\\Side_quests\\UF2MagIC\\UF2MagIC\n"
     ]
    }
   ],
   "source": [
    "# save files for demag_gui\n",
    "savepath = './'\n",
    "\n",
    "if not savepath.endswith('/'): savepath += '/'\n",
    "with open(savepath+'sites.txt', 'w') as sites_file:\n",
    "    sites_file.write('tab\\tsites\\n')\n",
    "sites_df = pd.DataFrame(sites_dict)\n",
    "sites_df.to_csv(savepath+'sites.txt',mode='a',index=False,sep='\\t')\n",
    "    \n",
    "with open(savepath+'samples.txt', 'w') as samples_file:\n",
    "    samples_file.write('tab\\tsamples\\n')\n",
    "samples_df = pd.DataFrame(samples_dict)\n",
    "samples_df.to_csv(savepath+'samples.txt',mode='a',index=False,sep='\\t')\n",
    "\n",
    "with open(savepath+'specimens.txt', 'w') as specimens_file:\n",
    "    specimens_file.write('tab\\tspecimens\\n')\n",
    "specimens_df = pd.DataFrame(specimens_dict)\n",
    "specimens_df.to_csv(savepath+'specimens.txt',mode='a',index=False,sep='\\t')\n",
    "\n",
    "with open(savepath+'measurements.txt', 'w') as measurements_file:\n",
    "    measurements_file.write('tab\\tmeasurements\\n')\n",
    "measurement_df = pd.DataFrame(measurement_dict)\n",
    "measurement_df = measurement_df[(~measurement_df['specimen'].isna())]\n",
    "#measurement_df = measurement_df.sort_values(by=['specimen','sequence'])\n",
    "measurement_df.to_csv(savepath+'measurements.txt',mode='a',index=False,sep='\\t')\n",
    "\n",
    "print('Files for pmagpy GUI saved to', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba0406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d077167",
   "metadata": {},
   "source": [
    "# Combine Magic files of multiple batches:\n",
    "\n",
    "Needs more testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaac6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give the links to the directories where measurements, specimens, samples, sites (etc) files are located\n",
    "links_to_individual_batches = {\n",
    "    r'G:\\My Drive\\__Postdoc\\Misc\\Side_quests\\UF2MagIC\\Testdata\\PI-IZZI',\n",
    "    r'G:\\My Drive\\__Postdoc\\Misc\\Side_quests\\UF2MagIC\\Testdata\\PI-PTSD'\n",
    "}\n",
    "save_dir = './' #link to where the combined magic files should be saved\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "try:\n",
    "    del measurements_df\n",
    "    del specimens_df\n",
    "    del samples_df\n",
    "    del sites_df\n",
    "    if not save_dir.endswith('/'): save_dir += '/'\n",
    "except: \n",
    "    if not save_dir.endswith('/'): save_dir += '/'\n",
    "\n",
    "\n",
    "for link in links_to_individual_batches:\n",
    "    if not link.endswith('/'): link += '/'\n",
    "    print('! Working on batch in '+link)\n",
    "    for magicfile in os.listdir(link):\n",
    "        if magicfile == 'sites.txt':\n",
    "            \n",
    "            try: \n",
    "                #sites_dict = {'site': [], 'method_codes': [], 'citations': []}\n",
    "                unique_sites = list(set(sites_df['site'])).astype(str) # check if df exists\n",
    "                temp_df = pd.read_csv(link+magicfile,skiprows=1,delimiter=('\\t'))\n",
    "                if len(temp_df[temp_df['sites'].isin(unique_sites)]) == 0:\n",
    "                    sites_df = pd.concat([sites_df,temp_df],ignore_index=True)\n",
    "                else: \n",
    "                    sites_df = pd.concat([sites_df,temp_df[~temp_df['sites'].isin(unique_sites)]],ignore_index=True)\n",
    "                    temp_df = temp_df[temp_df['sites'].isin(unique_sites)]                \n",
    "                    \n",
    "                    for key in ['method_codes','citations']:\n",
    "                        for i in range(len(temp_df)):\n",
    "                            if not temp_df.loc[temp_df.index[i],key] in sites_df.loc[sites_df['site']==temp_df.loc[temp_df.index[i],'site'],[key]]:\n",
    "                                sites_df.loc[sites_df['site']==temp_df.loc[temp_df.index[i],'site',[key]]] += ':'+temp_df.loc[temp_df.index[i],key]\n",
    "\n",
    "            except: # first batch -> dataframe\n",
    "                sites_df = pd.read_csv(link+magicfile,skiprows=1,delimiter=('\\t'))                    \n",
    "\n",
    "           \n",
    "        elif magicfile == 'samples.txt':\n",
    "            #samples_dict = {'site': [], 'sample': [],'method_codes': [], 'citations': [],\n",
    "            #    'azimuth': [], 'dip': [], 'bed_dip_direction': [], 'bed_dip': [],'result_quality': []}\n",
    "            try:\n",
    "                unique_samples = list(set(samples_df['sample'])) # check if df exists\n",
    "                temp_df = pd.read_csv(link+magicfile,skiprows=1,delimiter=('\\t'))\n",
    "                if len(temp_df[temp_df['sample'].isin(unique_samples)]) == 0:\n",
    "                    samples_df = pd.concat([samples_df,temp_df],ignore_index=True)\n",
    "                else: \n",
    "                    samples_df = pd.concat([samples_df,temp_df[~temp_df['sample'].isin(unique_samples)]],ignore_index=True)\n",
    "                    temp_df = temp_df[temp_df['sample'].isin(unique_samples)]                \n",
    "                    \n",
    "                    for key in ['method_codes','citations']:\n",
    "                        for i in range(len(temp_df)):\n",
    "                            if not temp_df.loc[temp_df.index[i],key] in samples_df.loc[samples_df['sample']==temp_df.loc[temp_df.index[i],'sample'],[key]]:\n",
    "                                samples_df.loc[samples_df['sample']==temp_df.loc[temp_df.index[i],'sample',[key]]] += ':'+temp_df.loc[temp_df.index[i],key]\n",
    "                    \n",
    "                    for key in ['site','azimuth','dip','bed_dip_direction','bed_dip']: # data checks. no changes to file\n",
    "                        for i in range(len(temp_df)):\n",
    "                            if not temp_df.loc[temp_df.index[i],key] in samples_df.loc[samples_df['sample']==temp_df.loc[temp_df.index[i],'sample'],[key]]:\n",
    "                                print('!WARNING! Sample '+temp_df.loc[temp_df.index[i],'sample']+' has multiple values for '+key+'!')\n",
    "                                                    \n",
    "            except:\n",
    "                samples_df = pd.read_csv(link+magicfile,skiprows=1,delimiter=('\\t'))\n",
    "                \n",
    "                \n",
    "        elif magicfile == 'specimens.txt':\n",
    "            #specimens_dict = {'specimen': [], 'sample': [],'method_codes': [],'experiments': [],'volume': [],\n",
    "            #   'citations': [],'result_quality':[]}\n",
    "            try:\n",
    "                unique_specimens = list(set(specimens_df['specimen'])) # check if df exists\n",
    "                temp_df = pd.read_csv(link+magicfile,skiprows=1,delimiter=('\\t'))\n",
    "                if len(temp_df[temp_df['specimen'].isin(unique_specimens)]) == 0:\n",
    "                    specimens_df = pd.concat([specimens_df,temp_df],ignore_index=True)\n",
    "                else: \n",
    "                    print('! check data for specimen '+ ','.join(list(temp_df['specimen']))+'! Did you do multiple experiments on it?')\n",
    "                    specimens_df = pd.concat([specimens_df,temp_df[~temp_df['specimen'].isin(unique_specimens)]],ignore_index=True)\n",
    "                    temp_df = temp_df[temp_df['specimen'].isin(unique_specimens)]                                                \n",
    "\n",
    "                    for key in ['method_codes','citations','experiments']:\n",
    "                        for i in range(len(temp_df)):\n",
    "                            if not temp_df.loc[temp_df.index[i],key] in specimens_df.loc[specimens_df['specimen']==temp_df.loc[temp_df.index[i],'specimen'],[key]]:\n",
    "                                specimens_df.loc[specimens_df['specimen']==temp_df.loc[temp_df.index[i],'specimen',[key]]] += ':'+temp_df.loc[temp_df.index[i],key]\n",
    "                    \n",
    "                    for key in ['sample','volume']: # data checks. no changes to file\n",
    "                        for i in range(len(temp_df)):\n",
    "                            if not temp_df.loc[temp_df.index[i],key] in specimens_df.loc[specimens_df['specimen']==temp_df.loc[temp_df.index[i],'specimen'],[key]]:\n",
    "                                print('!WARNING! Specimen '+temp_df.loc[temp_df.index[i],'specimen']+' has multiple values for '+key+'!')\n",
    "             \n",
    "            except:\n",
    "                specimens_df = pd.read_csv(link+magicfile,skiprows=1,delimiter=('\\t'))\n",
    "                \n",
    "                                                 \n",
    "        elif magicfile == 'measurements.txt':\n",
    "            try: # all entries should be combined(?)\n",
    "                len(measurements_df)\n",
    "                temp_df = pd.read_csv(link+magicfile,skiprows=1,delimiter=('\\t'))   \n",
    "                if not len(temp_df[temp_df['specimen'].isin(list(set(measurements_df['specimen'])))]) == 0:\n",
    "                     print('!WARNING! Specimen(s) '+''.join(temp_df[temp_df['specimen'].isin(list(set(measurements_df['specimen'])))])+' seem(s) to exist in multiple batches!')\n",
    "                measurements_df = pd.concat([measurements_df,temp_df],ignore_index=True)                \n",
    "            except:\n",
    "                measurements_df = pd.read_csv(link+magicfile,skiprows=1,delimiter=('\\t'))\n",
    "                \n",
    "                \n",
    "        elif magicfile == 'locations.txt':\n",
    "            print('! locations file found. Combine manually! I can\\'t be arsed')\n",
    "        else: print('! ignoring file '+ str(magicfile) + ' in ' + str(link))\n",
    "\n",
    "print('! data combined. cleaning up files...\\n')\n",
    "os.chdir(save_dir)                                                 \n",
    "with open('./sites.txt', 'w') as sites_file:\n",
    "    sites_file.write('tab\\tsites\\n')\n",
    "for i in range(len(sites_df)):\n",
    "    for key in sites_df.keys():\n",
    "        try:\n",
    "            if ':' in sites_df.loc[sites_df.index[i],key]: \n",
    "                sites_df.loc[sites_df.index[i],key] = ':'.join(list(set(sites_df.loc[sites_df.index[i],key].split(':'))))\n",
    "        except: continue\n",
    "sites_df.to_csv('./sites.txt',mode='a',index=False,sep='\\t')\n",
    "    \n",
    "with open('./samples.txt', 'w') as samples_file:\n",
    "    samples_file.write('tab\\tsamples\\n')\n",
    "for i in range(len(samples_df)):\n",
    "    for key in samples_df.keys():\n",
    "        try:\n",
    "            if ':' in samples_df.loc[samples_df.index[i],key]: \n",
    "                samples_df.loc[samples_df.index[i],key] = ':'.join(list(set(samples_df.loc[samples_df.index[i],key].split(':'))))\n",
    "        except: continue    \n",
    "samples_df.to_csv('./samples.txt',mode='a',index=False,sep='\\t')\n",
    "\n",
    "with open('./specimens.txt', 'w') as specimens_file:\n",
    "    specimens_file.write('tab\\tspecimens\\n')\n",
    "for i in range(len(specimens_df)):\n",
    "    for key in specimens_df.keys():\n",
    "        try:\n",
    "            if ':' in specimens_df.loc[specimens_df.index[i],key]:\n",
    "                specimens_df.loc[specimens_df.index[i],key] = ':'.join(list(set(specimens_df.loc[specimens_df.index[i],key].split(':'))))\n",
    "        except: continue\n",
    "specimens_df.to_csv('./specimens.txt',mode='a',index=False,sep='\\t')\n",
    "\n",
    "with open('./measurements.txt', 'w') as measurements_file:\n",
    "    measurements_file.write('tab\\tmeasurements\\n')\n",
    "measurements_df = measurements_df[(~measurements_df['specimen'].isna())]\n",
    "for i in range(len(measurements_df)):\n",
    "    for key in measurements_df.keys():\n",
    "        try:\n",
    "            if ':' in measurements_df.loc[measurements_df.index[i],key]: \n",
    "                measurements_df.loc[measurements_df.index[i],key] = ':'.join(list(set(measurements_df.loc[measurements_df.index[i],key].split(':'))))\n",
    "                \n",
    "        except: continue\n",
    "measurements_df.to_csv('./measurements.txt',mode='a',index=False,sep='\\t')\n",
    "\n",
    "print('Files for pmagpy GUI saved to', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88006b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c6dd920",
   "metadata": {},
   "source": [
    "# Ignore everything below unless you know what you are doing!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "JR6 -> Liverpool format for Shaw/pseudo-Thellier (PTSD-protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc8f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "file = 'PI-PTSD-pottery-pilot-edit.jr6'\n",
    "volume = 7 #cc\n",
    "\n",
    "meta = {\n",
    "    'section_code': 'TS',\n",
    "    'measurer': 'Daniele Thallner',\n",
    "    'density': 2.5,\n",
    "    'experiment': 'AFTH',\n",
    "    'bias': 60, #TRM bias field (uT)\n",
    "    'temp': 620, #TRM max temp (C)\n",
    "    'ARM_bias': 40, #ARM bias field (uT)\n",
    "    'comment': '',\n",
    "    'lat': 29.6, #GD: 45.9 , SC: 50, VT: 51, BB: 56, NW: 65.2\n",
    "    'lon': 278, #GD: 280.0, SC: 302, VT: 24, BB: 356, NW: 234\n",
    "    'ignore_chars': 0, #number of characters at the start of sample names that will be ignored\n",
    "    'step': 'NRM0',  # type of the first treatment in file (has to be in steps_all)\n",
    "    'steps_all': ['NRM0','ACQ0','ARM0','TRM1','ACQ1','ARM1','TRM2','ARM2'] # used protocol #,'ACQ0','ACQ1'\n",
    "    }   \n",
    "\n",
    "if not path.endswith('/'): path += '/'\n",
    "f = open(path+file)\n",
    "file = f.readlines()\n",
    "f.close()\n",
    "for line in file:\n",
    "    line = line[:9].strip(' ') + line[9:].replace('-',',-').replace(' ',',').replace('\\t',',')\n",
    "    while ',,' in line:\n",
    "        line=line.replace(',,',',')\n",
    "    with open('temp.txt','a') as tempfile:\n",
    "        tempfile.write(line)\n",
    "f = open('temp.txt')\n",
    "file = f.readlines()\n",
    "f.close()\n",
    "os.remove('temp.txt')\n",
    "samplelist = []\n",
    "for i in range(len(file)):\n",
    "    file[i] = file[i].split(',')\n",
    "    if not file[i][0] in samplelist: \n",
    "        samplelist.append(file[i][0])\n",
    "        with open('temp.txt','a') as tempfile:\n",
    "            tempfile.write(','.join(file[i]))\n",
    "        for j in range(i+1,len(file)):\n",
    "            temp = file[j].split(',')\n",
    "            if temp[0] == samplelist[-1]:\n",
    "                with open('temp.txt','a') as tempfile:\n",
    "                    tempfile.write(','.join(temp))\n",
    "f = open('temp.txt')\n",
    "file = f.readlines()\n",
    "f.close()\n",
    "os.remove('temp.txt')\n",
    "\n",
    "pthells = []\n",
    "for i in range(len(file)):\n",
    "    file[i] = file[i].strip('\\n').split(',')\n",
    "    if i == 0 or not file[i][0] == file[i-1][0]:\n",
    "        header, body, end = {},{'a':[]},{'a':'END'}\n",
    "        step, stepnr = 0, 0\n",
    "        if len(file[i][0]) > 9:\n",
    "                file[i][0] = file[i][0][-10:]\n",
    "        header['a'] = file[i][0][meta['ignore_chars']:]#+'.'+meta['steps_all'][step] #'sample_code'\n",
    "        header['b'] = 0 #'dip'\n",
    "        header['c'] = 90 #'yetn'\n",
    "        header['d'] = 0 #'height'\n",
    "        header['e'] = 0 #'position'\n",
    "        if np.isnan(header['e']) :\n",
    "            header['e'] = 0\n",
    "        header['f'] = 0 #thickness\n",
    "        header['g'] = 0 #unit dip\n",
    "        if np.isnan(header['g']) :\n",
    "            header['g'] = 0\n",
    "        header['h'] = 0 # unit dir\n",
    "        if np.isnan(header['h']) :\n",
    "            header['h'] = 360\n",
    "        header['i'] = meta['lat']#site lat\n",
    "        header['j'] = meta['lon']#site lon\n",
    "        if meta['step'][0] == 'T':\n",
    "            header['k'] = 'THAF-'+meta['experiment']\n",
    "        else: header['k'] = 'AF-D'   \n",
    "        header['l'] = ''+meta['measurer'] #analyst\n",
    "        header['m'] = 'JR6' #magnetometer\n",
    "        header['n'] = 'AF' #demagnetiser\n",
    "        header['o'] = '' #comment\n",
    "        if not type(header['o']) == str:\n",
    "            if np.isnan(header['o']):\n",
    "                header['o'] = 0 \n",
    "        header['p'] = '!!!NOT UPLOADED!!!'\n",
    "        header['q'] = '!!!NOT CONVERTED!!!'\n",
    "        header['r'] = volume #volume\n",
    "        header['s'] = meta['density']*1000 #density\n",
    "    if i >= 0:\n",
    "        if (len(body['a']) > 1 and not file[i][1][:2] == file[i-1][1][:2]) and not stepnr == 1:\n",
    "            step = step+1\n",
    "            stepnr = 0\n",
    "        #elif 'AD' in file[i][1]and 'AD' in file[i-1] and float(file[i][1].strip('AD')) < float(file[i-1][1].strip('AD')):\n",
    "        #    step = step+1 # if the file consists of more sets of AF measurements\n",
    "        #    stepnr = 0\n",
    "        #if len(file[i][-1]) < 10: print('ERROR! Check the jr6 file of', header['a'],'(probably fucked up import)')\n",
    "        \n",
    "        if 'NRM' in file[i][1]: tempfield = 0\n",
    "        elif 'AD' in file[i][1]: tempfield = int(float(file[i][1].strip('AD')))\n",
    "        elif 'ARM' in file[i][1]: tempfield = int(float(file[i][1].strip('ARM')))\n",
    "        elif 'TRM' in file[i][1]: tempfield = int(float(file[i][1].strip('TRM')))\n",
    "        else: tempfield = 0\n",
    "        try: body['a'].append(tempfield) # temperature/field\n",
    "        except: body['a'] = [tempfield]\n",
    "        \n",
    "        try: body['b'].append(0) # MW power\n",
    "        except: body['b'] = [0]\n",
    "        try: body['c'].append(0) # MW time\n",
    "        except: body['c'] = [0]\n",
    "        try: body['d'].append(float(file[i][2])*10**int(file[i][5])) #x (nAm2) A/m!\n",
    "        except: body['d'] = [float(file[i][2])*10**int(file[i][5])]\n",
    "        try: body['e'].append(float(file[i][3])*10**int(file[i][5])) #y (nAm2) A/m!\n",
    "        except: body['e'] = [float(file[i][3])*10**int(file[i][5])]\n",
    "        try: body['f'].append(float(file[i][4])*10**int(file[i][5])) #z (nAm2) A/m!\n",
    "        except: body['f'] = [float(file[i][4])*10**int(file[i][5])]\n",
    "        try: body['g'].append(float(header['r'])*float(header['s'])/1000) #mass\n",
    "        except: body['g'] = [float(header['r'])*float(header['s'])/1000]\n",
    "        try: body['h'].append(meta['ARM_bias']) #applied field intensity uT\n",
    "        except: body['h'] = [meta['ARM_bias']]\n",
    "        try: body['i'].append(0) #applied field dec\n",
    "        except: body['i'] = [0]\n",
    "        if body['h'][-1] > 0:\n",
    "            try: body['j'].append(90) #applied field inc\n",
    "            except: body['j'] = [90]\n",
    "        else:\n",
    "            try: body['j'].append(0) #applied field inc\n",
    "            except: body['j'] = [0]\n",
    "        datetime = ''#file[i][-1].split(' ')\n",
    "        try: body['k'].append(datetime) #measurement date\n",
    "        except: body['k'] = [datetime]\n",
    "        try: body['l'].append(datetime) #measurement time\n",
    "        except: body['l'] = [datetime] # if len(datetime[1]) < 0 ?\n",
    "        try: body['m'].append(meta['steps_all'][step]) #comment\n",
    "        except: \n",
    "            body['m'] = [meta['steps_all'][step]]\n",
    "        if 'TRM1' in meta['steps_all'][step] or 'TRM2' in meta['steps_all'][step]:\n",
    "            header['o'] = 'Shaw-TRM with '+ str(meta['bias']) +'uT at '+ str(meta['temp']) +'C'\n",
    "        elif 'ACQ0' in meta['steps_all'][step]:\n",
    "            header['o'] = 'pseudo-Thellier experiment'\n",
    "        if ('ACQ0' in meta['steps_all'][step] or 'ACQ1' in meta['steps_all'][step]) and not file[i][0] in pthells: pthells.append(file[i][0])\n",
    "        try: body['n'].append(stepnr) #step number\n",
    "        except: body['n'] = [stepnr]\n",
    "        stepnr+=1\n",
    "        if 'NRM' in file[i][1]: \n",
    "            try: body['o'].append('NRM') #steptype\n",
    "            except: body['o'] = ['NRM']\n",
    "        else:\n",
    "            if 'ARM' in file[i][1]:\n",
    "                try: body['o'].append('I') #steptype\n",
    "                except: body['o'] = ['I']\n",
    "            else:\n",
    "                try: body['o'].append('Z') #steptype\n",
    "                except: body['o'] = ['Z']\n",
    "                body['h'][-1] = 0\n",
    "        try: body['p'].append(0) #tristan gain\n",
    "        except: body['p'] = [0]\n",
    "        try: body['q'].append(0) #MW integral\n",
    "        except: body['q'] = [0]\n",
    "        try: body['r'].append(file[i][-1]) #jr6 error\n",
    "        except: body['r'] = [file[i][-1]]\n",
    "        try: body['s'].append(file[i][-1]) #Fit\n",
    "        except: body['s'] = [file[i][-1]]\n",
    "        try: body['t'].append(file[i][-1]) #Utrecht error\n",
    "        except: body['t'] = [file[i][-1]]\n",
    "        if 'TRM' in file[i][1]:\n",
    "            try: body['u'].append(0) #af peak field\n",
    "            except: body['u'] = [0]\n",
    "        else:\n",
    "            try: body['u'].append(tempfield) #af peak field\n",
    "            except: body['u'] = [tempfield]\n",
    "        if 'TRM' in file[i][1]:\n",
    "            try: body['v'].append(tempfield) #th peak field\n",
    "            except: body['v'] = [tempfield]\n",
    "        else:\n",
    "            try: body['v'].append(0) #th peak field\n",
    "            except: body['v'] = [0]\n",
    "                        #print(header['a'],file[i][0],body['m'][-1])\n",
    "        if len(body['a'])>1:\n",
    "            if body['a'][-1] == body['a'][-2] and body['m'][-1] == body['m'][-2]:\n",
    "                print('! double step found for sample',header['1'])\n",
    "                print(file[i])\n",
    "    if i < len(file)-1 or i == len(file)-1:\n",
    "        if i == len(file)-1 or not file[i][0] == file[i+1].split(',')[0]:\n",
    "            head = pd.DataFrame(header, index = [0])\n",
    "            head.loc[head.index[0], 'a'] = head.loc[head.index[0], 'a']\n",
    "            head.to_csv('./'+meta['section_code']+'_PTSD.csv', index = False, header=False, mode = 'a')\n",
    "            body_df = pd.DataFrame(body)\n",
    "            body_df.to_csv('./'+meta['section_code']+'_PTSD.csv', index = False, header=False, mode = 'a')\n",
    "            end_df = pd.DataFrame(end, index = [0])\n",
    "            end_df.to_csv('./'+meta['section_code']+'_PTSD.csv', index = False, header=False, mode = 'a')\n",
    "            print(header['a'] + ' converted! \\()/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29161fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_residual(file,mode):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    h = open('./temp.csv',mode='a')\n",
    "    datalines = []\n",
    "    for line in lines:\n",
    "        line = line.strip(' ').split(',')\n",
    "        try: \n",
    "            float(line[20].strip(' '))\n",
    "            datalines.append(line)\n",
    "            if line[12] == mode:\n",
    "                nx = float(datalines[-1][3])\n",
    "                ny = float(datalines[-1][4])\n",
    "                nz = float(datalines[-1][5])\n",
    "                px, py, pz = 0,0,0\n",
    "            elif line[12] == 'ACQ'+str(mode[-1]) and px == 0 and py == 0 and pz == 0:\n",
    "                px = float(datalines[-1][3])\n",
    "                py = float(datalines[-1][4])\n",
    "                pz = float(datalines[-1][5])\n",
    "            elif line[12] == 'ARM' + str(mode[-1]):\n",
    "                ax = float(datalines[-1][3])\n",
    "                ay = float(datalines[-1][4])\n",
    "                az = float(datalines[-1][5])\n",
    "        except:\n",
    "            if not 'END' in line[0]:\n",
    "                templine = ''\n",
    "                for i in range(len(line)):\n",
    "                    templine += line[i].strip(' ') + ','\n",
    "                h.write(templine[:-1])\n",
    "                datalines = []\n",
    "            else:\n",
    "                for entry in datalines:\n",
    "                    if entry[12] == mode:\n",
    "                        entry[3] = float(entry[3]) - nx\n",
    "                        entry[4] = float(entry[4]) - ny\n",
    "                        entry[5] = float(entry[5]) - nz\n",
    "                    elif entry[12] == 'ACQ'+str(mode[-1]):\n",
    "                        entry[3] = float(entry[3]) - px\n",
    "                        entry[4] = float(entry[4]) - py\n",
    "                        entry[5] = float(entry[5]) - pz\n",
    "                    elif entry[12] == 'ARM' + str(mode[-1]):\n",
    "                        entry[3] = float(entry[3]) - ax \n",
    "                        entry[4] = float(entry[4]) - ay\n",
    "                        entry[5] = float(entry[5]) - az\n",
    "                    templine = ''\n",
    "                    for i in range(len(entry)):\n",
    "                        templine += str(entry[i]).strip(' ') + ','\n",
    "                    h.write(templine[:-1])\n",
    "    print('Residuals have been removed! ( )')\n",
    "    h.close()\n",
    "    \n",
    "def pTH_online(file, noresid = True,mode='NRM0'):\n",
    "    if noresid:\n",
    "        remove_residual(file,mode)\n",
    "        f = open('./temp.csv')\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "        os.remove('./temp.csv')\n",
    "        h = open('./'+file[:6]+'upload_noResidual.txt',mode='a')\n",
    "    else:\n",
    "        f = open(file)\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "        h = open('./'+file[:6]+'upload.txt',mode='a')\n",
    "    text = 'specimen\\tstep\\tdec_s\\tinc_s\\tmoment\\ttype\\n'\n",
    "    h.write(text)\n",
    "    #name,vol = '',0\n",
    "    name = ''\n",
    "    for line in lines:\n",
    "        text = ''\n",
    "        line = line.split(',')\n",
    "        try:\n",
    "            step = float(line[20])\n",
    "            if line[12] == mode or line[12] == 'ACQ'+str(mode[-1]) or line[12] == 'ARM' + str(mode[-1]):\n",
    "                #step = tmp/10\n",
    "                #if not float(line[3]) == 0 and not float(line[4]) == 0 and not float(line[5]) == 0:\n",
    "                try:\n",
    "                    if not float(line[3]) == 0 and not float(line[4]) == 0:\n",
    "                        dec = (np.arctan2(float(line[4]),float(line[3]))*180/np.pi)%360\n",
    "                    else:\n",
    "                        dec = tempdec\n",
    "                    #if((float(line[3]) < 0 and float(line[4]) > 0) or (float(line[3]) < 0 and float(line[4]) < 0)):\n",
    "                    #    dec = dec + 180\n",
    "                    #elif(float(line[3]) > 0 and float(line[4]) < 0):\n",
    "                    #    dec = dec + 360\n",
    "                    if not float(line[5]) == 0:\n",
    "                        inc = np.arctan2(float(line[5]),np.sqrt(float(line[3])**2+float(line[4])**2))*180/np.pi\n",
    "                    else:\n",
    "                        inc = tempinc\n",
    "                    moment = np.sqrt(float(line[3])**2+float(line[4])**2+float(line[5])**2)# * vol * 10**6 # emu/cc to nAm2 (convert PTSD already converts emu to nAm2)\n",
    "                    tempdec, tempinc = dec, inc\n",
    "                #else:\n",
    "                except:\n",
    "                    dec, inc, moment = tempdec,tempinc,0\n",
    "                    print(line)\n",
    "                if line[12] == mode:\n",
    "                    steptype = 0\n",
    "                elif line[12] == 'ACQ'+str(mode[-1]):\n",
    "                    steptype = 6\n",
    "                elif line[12] == 'ARM'+str(mode[-1]):\n",
    "                    steptype = 7\n",
    "                text += name + '\\t' + str(step) + '\\t' + str(dec) +'\\t' + str(inc) + '\\t' + str(moment) +'\\t' + str(steptype)+'\\n'\n",
    "        except:\n",
    "            if not 'END' in line[0]:\n",
    "                name = line[0].strip(' ')\n",
    "                #vol = float(line[17])\n",
    "        h.write(text)\n",
    "        text = ''\n",
    "    h.close()\n",
    "    print('(    )*: paleointensity.org - pseudoThellier-uploadfile (pth format) created!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217216f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 'NRM0'\n",
    "\n",
    "if len(pthells) == 0: print('No specimens to convert')\n",
    "f = open('./'+meta['section_code']+'_PTSD.csv')\n",
    "ptsdfile = f.readlines()\n",
    "f.close()\n",
    "header,body, = {},{}\n",
    "    \n",
    "pth = False\n",
    "for line in ptsdfile:\n",
    "    line = line.split(',')\n",
    "    if line[0] in pthells:\n",
    "        pth = True\n",
    "        for i in range(len(line)):\n",
    "            header[str(i)] = line[i].strip('\\n')\n",
    "        head = pd.DataFrame(header, index = [0])\n",
    "        head.to_csv('./pth_temp.csv', index = False, header=False, mode = 'a')\n",
    "    elif 'END' in line[0]:\n",
    "        end_df.to_csv('./pth_temp.csv', index = False, header=False, mode = 'a')\n",
    "        pth = False\n",
    "    else:\n",
    "        if pth == True:\n",
    "            for i in range(len(line)):\n",
    "                body[str(i)] = line[i].strip('\\n')\n",
    "                if 'TRM' in line[12]: body['0'] = 0\n",
    "            body_df = pd.DataFrame(body, index = [0])\n",
    "            body_df.to_csv('./pth_temp.csv', index = False, header=False, mode = 'a')\n",
    "            \n",
    "pTH_online('./pth_temp.csv', noresid = True, mode=start)\n",
    "os.remove('./pth_temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c81a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b44541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
